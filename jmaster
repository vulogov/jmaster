#!/usr/bin/env python3

import time
import sys
import yaml
import fnmatch
import expression
import posixpath
import os.path
import dpath.util
import hy
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
from clint.arguments import Args
from clint.textui import colored
from clint.textui import puts, indent
from clint.textui import progress
from tabulate import tabulate
import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
sns.set()

HELP="""
jmaster - application for generation test datasets for ML
Usage: jmaster (keys) --models (list of model YAML files)

    Keys:

        --exp ( jmaster expression )
            Evaluate jmaster expression and display an output
        --output ( filename )
            Set the final output to a file.
            Default: output.csv
        --oexp (list of expressions )
            Performing computations with generated models and save result to
            the file specified by "--output"
        --ts (list of files)
            The models will be a recalculation of preloaded files. Size of the
            attribute will define the number of new data sets
        --op operator
            Operator which will be applicable to the columns in --ts mode
            Default: multiplication
            Possible options: multiply, plus, minus, divide
        --split float
            Define test/train split ratio
        --target name
            Set the name for the Y target in training set
        --help
            Display help

"""

EXAMPLES = """
    Examples:

        1. jmaster --models test.yaml
            Load model file "yest.yaml", generate test dataset and save the output
            into a CSV file with the name secified in "fname" attribute of the model
        2. jmaster --exp "sum(range(2,10,3))"
            Perform evaluation of the expression and display the result to STDOUT
        3. jmaster --output model.csv --oexp "merge(test1, test2)" --models test1.yaml test2.yaml
            Load and generate models "test1.yaml" and "test2.yaml" and then perform
            calculation with generated models "merge(test1, test2)" with saving result
            into a file "model.csv"
        4.  jmaster --models test.yaml --ts model.csv
            Load data from "model.csv" and model from "test.yaml" and produce new
            series of the data, derived from preloaded data and computations of the
            model. Series of data generated from the model, is applying to original data as
            through operators.

"""

YAML = """
# This is an example of the model file. The model begins
# with node "model:"
    model:
      # ID of the model
      id: test1
      # Human-readable name of the model
      name: "Test model"
      # Name of the CSV file for storing generated test data
      fname: test_1.csv
      # Definition of the attributes of the model
      attrs:
        # Attribute name and expression for generation of the column
        - a: "abs(random_normal(1, 12, 10))"
        - b: "abs(random_normal(2, 8, 10))"
      # Definition of the "y" column of the data
      y: "abs(random_normal(0, 4, 10))"
      # Non-mandatory post-processing expressions
      postprocess:
        - "normalize(data)"
"""

def _normalize(data):
    _post = preprocessing.normalize(data)
    _data = pd.DataFrame()
    c = 0
    for k in data:
        _data[k] = _post[c]
        c += 1
    data = _data
    return data

def _merge_df(*datasets):
    root = pd.DataFrame()
    for d in datasets:
        root = root.append(d)
    return root


def _anexpression(_exp, _fun, variables={}):
    parser = expression.Expression_Parser(functions=_fun, variables=variables)
    try:
        return parser.parse(_exp)
    except NameError:
        print("Name error:",colored.red(_exp))
        return None
    except TypeError:
        print("Type error:",colored.red(_exp))
        return None
    except SyntaxError:
        print("Syntax error:",colored.red(_exp))
        return None

def _expression(_exp, variables={}):
    functions = {
        'int': np.int,
        'odd': lambda x: True if x % 2 == 0 else False,
        'even': lambda x: True if x % 2 == 1 else False,
        'div2': lambda x: x % 2,
        'range': np.arange,
        'abs':abs,
        'sum':np.sum,
        'sin':np.sin,
        'cos':np.cos,
        'log':np.log,
        'log10':np.log10,
        'sqrt':np.sqrt,
        'random_normal': np.random.normal,
        'random_uniform': np.random.uniform,
        'random_int': np.random.randint,
        'normalize': lambda x: x / np.linalg.norm(x)
    }
    return _anexpression(_exp, functions, variables)

def _lispex(_exp_list, vars):
    vars['np'] = np
    out = {}
    for k in _exp_list:
        _key = list(k.keys())[0]
        _value = k[_key]
        expr = hy.read_str(_value)
        vars[_key] = hy.eval(expr, vars)
        out[_key] = vars[_key]
    return out

def _outexpression(_exp, variables):
    functions = {
        "merge": _merge_df
    }
    res = _anexpression(_exp, functions, variables)
    return res

def _mk_heatmap(namespace, fname, data):
    data.reset_index(inplace=True, drop=True)
    plot = sns.heatmap(data, annot=True, linewidths=.5, cmap="coolwarm", fmt=".1f")
    png_fname = os.path.splitext(fname)[0]+'.png'
    fig = plot.get_figure()
    fig.savefig(png_fname)
    fig.clf()
    plot = sns.catplot(kind="box", data=data)
    png_fname = os.path.splitext(fname)[0]+"_cat"+'.png'
    plot.savefig(png_fname)

def _load_vars_from_model(namespace, model, vars):
    if 'variables' not in model['model']:
        model['model']['variables'] = []
    if 'pre_func' not in model['model']:
        model['model']['pre_func'] = []
    if 'post_func' not in model['model']:
        model['model']['post_func'] = []
    _lispex(model['model']['pre_func'], vars)
    for v in model['model']['variables']:
        _key = list(v.keys())[0]
        _value = v[_key]
        vars[_key] = _expression(_value, vars)
    _lispex(model['model']['post_func'], vars)

def _train_keras(namespace, model, fname, data):
    print(colored.white("Building KERAS model"))
    tts = dpath.util.get(namespace, "/config/train_test_split")
    target = dpath.util.get(namespace, "/config/target_column")
    if 'keras' not in model:
        print("Error building Keras ML. model not defined: ", colored.red(model['name']))
        return namespace
    keras_model = model['keras']
    random_state = keras_model.get('random_state', dpath.util.get(namespace, "/config/random_state"))
    if target not in data:
        print("Error building Keras ML. Target not existing: ", colored.red(target))
        return namespace
    target = [target,]
    predictors = list(set(list(data.columns))-set(target))
    data[predictors] = keras.utils.normalize(data[predictors])
    X = data[predictors].values
    y = data[target].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tts, random_state=40)
    layers = list(keras_model.get('layers', {}).keys())
    layers.sort()
    l = keras_model.get('layers', {})
    model = Sequential()
    ln = 0
    isOK = True
    lastLayer = None
    y_train = to_categorical(y_train)
    y_test = to_categorical(y_test)
    if y_train.shape[1] != y_test.shape[1]:
        print("Error building Keras ML Y(train) and Y(test) shape not matching: ", colored.red(y_train.shape), colored.red(y_test.shape))
        return namespace
    for layer in layers:
        ld = l[layer]
        lv = {}
        lastLayer = lv
        for k in ld:
            _k = list(k.keys())[0]
            _v = k[_k]
            lv[_k] = _v
        if lv.get('type', 'Dense') == 'Dense':
            layer_size = lv.get('n', None)
            if layer_size is None:
                layer_size = y_test.shape[1]
                lv['n'] = layer_size
                print("Set layer output size: ", colored.magenta(layer_size), colored.magenta(y_test.shape))
            if ln == 0:
                model.add(Dense(lv.get('n', 100), activation=lv.get('activation', 'relu'), input_dim=len(predictors)))
            else:
                model.add(Dense(layer_size, activation=lv.get('activation', 'relu')))
        else:
            print("Error building Keras ML. Unknown layer type: ", colored.red(lv.get('type', 'Dense')))
            isOK = False
            continue
        ln += 1
    if isOK is not True:
        print(colored.red("Building KERAS model unsuccesful"))
        return namespace
    count_classes = y_test.shape[1]
    print("Number of the target classes: ", colored.magenta(count_classes))
    print("Last layer output: ", colored.magenta(lastLayer.get("n", 0)))
    if count_classes != lastLayer.get("n", 0):
        print("Number of the target classes doesn't match with Y size: ", colored.red(y_test.shape[1], lastLayer.get("n", 0)))
        return namespace
    compile_opt = {}
    for k in keras_model.get("compile", {}):
        _k = list(k.keys())[0]
        _v = k[_k]
        compile_opt[_k] = _v
    optimizer = compile_opt.get('optimizer', 'adam')
    loss = compile_opt.get('loss', 'categorical_crossentropy')
    metrics = compile_opt.get('metrics', ['accuracy'])
    print(colored.white("Compiling model"))
    model.compile(optimizer=optimizer,
              loss=loss,
              metrics=metrics)
    print(colored.white("Training model"))
    model.fit(X_train, y_train, epochs=keras_model.get("epochs", 20))
    pred_train= model.predict(X_train)
    scores = model.evaluate(X_train, y_train, verbose=0)
    print('Accuracy on training data: ', colored.green(scores[1]))
    print('Error on training data: ', colored.green(1-scores[1]))
    pred_test= model.predict(X_test)
    scores2 = model.evaluate(X_test, y_test, verbose=0)
    print('Accuracy on test data: ', colored.green(scores2[1]))
    print('Error on test data: ', colored.green(1-scores2[1]))
    fname = os.path.splitext(fname)[0]+'.h5'
    print('Saving KERAS model: ', colored.green(fname))
    model.save(fname)



def _train_test_split(namespace, fname, data):
    tts = dpath.util.get(namespace, "/config/train_test_split")
    _fname = os.path.splitext(fname)[0]
    _fname_test = "{}_test.csv".format(_fname)
    _fname_train = "{}_train.csv".format(_fname)
    train, test = train_test_split(data, test_size=tts)
    print("Saving training: ", colored.green(_fname_train))
    train.to_csv(_fname_train, index=False)
    print("Saving testing: ", colored.green(_fname_test))
    test.to_csv(_fname_test, index=False)



def help(namespace, param):
    from pygments.formatters import TerminalFormatter
    from pygments import highlight
    from pygments.lexers.data import YamlLexer
    print(colored.cyan(HELP))
    print(colored.white(EXAMPLES))
    with indent(4):
        puts("Example of the model file:\n")
        with indent(4):
            puts(highlight(YAML, YamlLexer(), TerminalFormatter()))
    sys.exit(0)

def output(namespace, param):
    try:
        dpath.util.set(namespace, "/config/output", param[0])
    except IndexError:
        return namespace
    print("Set output file: ", colored.magenta(param[0]))
    return namespace

def split(namespace, param):
    try:
        dpath.util.set(namespace, "/config/train_test_split", float(param[0]))
    except IndexError:
        return namespace
    print("Set train/test split to: ", colored.magenta(param[0]))
    return namespace

def target(namespace, param):
    try:
        dpath.util.set(namespace, "/config/target_column", param[0])
    except IndexError:
        return namespace
    print("Set target column to: ", colored.magenta(param[0]))
    return namespace

def oexp(namespace, param):
    dpath.util.set(namespace, "/config/output_exp", param)
    print("Set output calculations: ", colored.magenta(param))
    return namespace

def exp(namespace, param):
    for e in param:
        _res = _expression(e)
        if _res is None:
            print(colored.red("Does not compute!"))
            continue
        print(colored.magenta(e), colored.white(" = "), colored.yellow(_res))
    return namespace

def tsmodel(namespace, params):
    df = []
    for i in params:
        df.append(pd.read_csv(i))
    c = 0
    models = dpath.util.get(namespace, "/models")
    fname = dpath.util.get(namespace, "/config/output")
    fname = os.path.splitext(fname)[0]
    op = dpath.util.get(namespace, "/config/op")
    op_fun = dpath.util.get(namespace, "/sbin/op")[op]
    for data in df:
        vars = {'data': data, 'shape':data.shape}
        for m in models:
            print("Applying",colored.green(m),"on", colored.green(params[c]), "with",colored.green(op))
            _d = {}
            if 'fun' in models[m]['model']:
                out = _lispex(models[m]['model']["fun"], vars)
                _d.merge(out)
            for e in models[m]['model']["attrs"]:
                _load_vars_from_model(namespace, models[m], vars)
                _exp = list(e.values())[0]
                _key = list(e.keys())[0]
                _mul = _expression(_exp, vars)
                _d[_key] = _mul
            if "y" in models[m]['model']:
                _d["y"] = _expression(models[m]['model']["y"], vars)
            for _ts_step in range(0, data.shape[0]):
                for _col_name in _d:
                    try:
                        data[_col_name] = op_fun(data[_col_name],_d[_col_name][_ts_step])
                    except KeyError as err:
                        print(colored.red("Attribute not found!"), "{}".format(err))
                        raise SystemExit
                if 'y' in data:
                    data["y"] = op_fun(data["y"], _d["y"][_ts_step])
                _current_fname = "{}_{}_{}.csv".format(fname, c, _ts_step)
                data.to_csv(_current_fname, index=False)
                _mk_heatmap(namespace, _current_fname, data)
                print("Saving",colored.green(_current_fname))
                _train_test_split(namespace, _current_fname, data)
        c += 1
    return namespace

def model(namespace, models):
    for m in dpath.util.get(namespace, "/models"):
        model = dpath.util.get(namespace, "/models")[m]['model']
        if 'fun' in model:
            n_of_fun = len(model['fun'])
        else:
            n_of_fun = 0
        n_of_attrs = len(model['attrs']) + n_of_fun
        print(tabulate(
            [["Model:", colored.yellow(m)],
            ["Generating: ", colored.yellow("{} attributes".format(n_of_attrs))]]
        ))
        if n_of_attrs == 0:
            return
        data = pd.DataFrame()
        vars = {'data': data}
        _load_vars_from_model(namespace, dpath.util.get(namespace, "/models")[m], vars)
        with progress.Bar(label=m, expected_size=n_of_attrs) as bar:
            last_val = 0
            if 'fun' in model:
                out = _lispex(model["fun"], vars)
                for k in out:
                    data[k] = out[k]
            for e in model['attrs']:
                _exp = list(e.values())[0]
                _key = list(e.keys())[0]
                bar.show(last_val)
                last_val += 1
                col = _expression(_exp, vars)
                if col is not None:
                    data[_key] = col
        if 'y' in model:
            _exp = model['y']
            print("Calculating Y: ", colored.green(_exp))
            col = _expression(_exp, vars)
            if col is not None:
                data['y'] = col
            else:
                print(colored.red("Failed"))
        else:
            print("Calculating Y: ", colored.cyan("Not defined in model"))
        if 'postprocess' in model:
            for _exp in model['postprocess']:
                print("Postprocessing: ", colored.green(_exp))
                data = _expression(_exp, vars)
        else:
            print("Postprocessing: ", colored.green("Not defined"))
        dpath.util.new(namespace, "/generated/{}".format(m), data)
        data.reset_index()
        try:
            print(colored.white("Save {}".format(model['fname'])))
            data.to_csv(model['fname'], index=False)
            _mk_heatmap(namespace, model['fname'], data)
            _train_test_split(namespace, model['fname'], data)
            _train_keras(namespace, model, model['fname'], data)
        except IOError:
            print(colored.red("Can not save {}".format(model['fname'])))
    return namespace

def calculate_output(namespace, params):
    variables = {
        'data': pd.DataFrame()
    }
    variables.update(dpath.util.get(namespace, "/generated"))
    for f in params:
        variables["data"] = _outexpression(f, variables)
    return variables["data"]

def get_params(namespace, name):
    try:
        params = dpath.util.get(namespace, "/config/grouped")['--{}'.format(name)].all
    except KeyError:
        params = []
    return params

def execute_fun(namespace, name, param):
    n = "/sbin/{}".format(name)
    try:
        print(colored.white("Executing "), colored.green("{}".format(n)))
        fun = dpath.util.get(namespace, n)
    except KeyError:
        print(colored.red("Can not excute {}".format(n)))
    namespace = fun(namespace, param)
    return namespace

def main():
    print(colored.white("Generating test datasets"))
    namespace = {}
    dpath.util.new(namespace, "/config/args", Args())
    dpath.util.new(namespace, "/config/flags", dpath.util.get(namespace, "/config/args").flags)
    dpath.util.new(namespace, "/config/grouped", dpath.util.get(namespace, "/config/args").grouped)
    dpath.util.new(namespace, "/config/output", "output.csv")
    dpath.util.new(namespace, "/config/output_exp", [])
    dpath.util.new(namespace, "/config/op", 'multiply')
    dpath.util.new(namespace, "/config/train_test_split", 0.2)
    dpath.util.new(namespace, "/config/target_column", "y")
    dpath.util.new(namespace, "/config/random_state", 40)
    dpath.util.new(namespace, "/models", {})
    dpath.util.new(namespace, "/generated", {})
    dpath.util.new(namespace, "/bin/help", help)
    dpath.util.new(namespace, "/bin/exp", exp)
    dpath.util.new(namespace, "/bin/output", output)
    dpath.util.new(namespace, "/bin/oexp", oexp)
    dpath.util.new(namespace, "/bin/oexp", oexp)
    dpath.util.new(namespace, "/bin/split", split)
    dpath.util.new(namespace, "/bin/target", target)
    dpath.util.new(namespace, "/sbin/model", model)
    dpath.util.new(namespace, "/sbin/ts", tsmodel)
    dpath.util.new(namespace, "/sbin/op", {'multiply':np.multiply, 'plus': np.add, 'minus':np.subtract, 'divide': np.divide})
    dpath.util.new(namespace, "/sbin/output", calculate_output)
    files = get_params(namespace, 'models')
    ts = get_params(namespace, 'ts')
    files = [i for i in files if posixpath.exists(i) and posixpath.isfile(i)]
    ts = [i for i in ts if posixpath.exists(i) and posixpath.isfile(i)]
    op = get_params(namespace, 'op')
    if len(op) == 0:
        op = 'multiply'
    else:
        op = op[0]
        if op not in dpath.util.get(namespace, "/sbin/op"):
            print(colored.red("Can not recognize operation for --ts mode: {}".format(op)))
            print(colored.red("Valid options are: {}".format(list(dpath.util.get(namespace, "/sbin/op").keys()))))
            return
    dpath.util.set(namespace, "/config/op", op)
    dpath.util.new(namespace, "/config/ts", ts)
    dpath.util.new(namespace, "/config/files", files)

    print("Considering", colored.green("{}".format(len(files))), "model(s)")
    for f in files:
        with open(f, 'r') as _f:
            try:
                y = yaml.safe_load(_f)
            except yaml.YAMLError as exc:
                continue
            if 'model' not in y:
                continue
            _isGood = True
            for i in ['fname', 'attrs', 'id']:
                if i not in y['model']:
                    print("Model {} no good: ".format(f), colored.red("{} attribute is missing".format(i)))
                    _isGood = False
                    break
            for i in ['y']:
                if i not in y['model']:
                    print("Model {} may not be complete: ".format(f), colored.cyan("{} attribute is missing".format(i)))
            if _isGood is not True:
                continue
            dpath.util.new(namespace, "/models/{}".format(y['model']['id']), y)
    for f in dpath.util.get(namespace, "/config/flags").all:
        try:
            fun = dpath.util.get(namespace, "/bin/{}".format(f[2:].lower()))
        except KeyError:
            continue
        except IndexError:
            continue
        param = dpath.util.get(namespace, "/config/grouped/{}".format(f)).all
        namespace = fun(namespace, param)
    if len(ts) > 0:
        namespace = execute_fun(namespace, "ts", ts)
    else:
        namespace = execute_fun(namespace, "model", files)
    output_exp = dpath.util.get(namespace, "/config/output_exp")
    if len(output_exp) != 0:
        fname = output_exp = dpath.util.get(namespace, "/config/output")
        print("Calculating output to: ", colored.green(fname))
        fun = dpath.util.get(namespace, "/sbin/output")
        data = fun(namespace, dpath.util.get(namespace, "/config/output_exp"))
        data.reset_index()
        print("Saving output to: ", colored.green(fname))
        data.to_csv(fname, index=False)
        _mk_heatmap(namespace, fname, data)
    return

if __name__ == '__main__':
    main()
