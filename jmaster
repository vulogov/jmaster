#!/usr/bin/env python3

import time
import sys
import yaml
import fnmatch
import expression
import posixpath
import os.path
import dpath.util
import hy
from clint.arguments import Args
from clint.textui import colored
from clint.textui import puts, indent
from clint.textui import progress
from tabulate import tabulate
import numpy as np
import pandas as pd
from sklearn import preprocessing
import seaborn as sns
import matplotlib.pyplot as plt
sns.set()

HELP="""
jmaster - application for generation test datasets for ML
Usage: jmaster (keys) --models (list of model YAML files)

    Keys:

        --exp ( jmaster expression )
            Evaluate jmaster expression and display an output
        --output ( filename )
            Set the final output to a file.
            Default: output.csv
        --oexp (list of expressions )
            Performing computations with generated models and save result to
            the file specified by "--output"
        --ts (list of files)
            The models will be a recalculation of preloaded files. Size of the
            attribute will define the number of new data sets
        --op operator
            Operator which will be applicable to the columns in --ts mode
            Default: multiplication
            Possible options: multiply, plus, minus, divide
        --help
            Display help

"""

EXAMPLES = """
    Examples:

        1. jmaster --models test.yaml
            Load model file "yest.yaml", generate test dataset and save the output
            into a CSV file with the name secified in "fname" attribute of the model
        2. jmaster --exp "sum(range(2,10,3))"
            Perform evaluation of the expression and display the result to STDOUT
        3. jmaster --output model.csv --oexp "merge(test1, test2)" --models test1.yaml test2.yaml
            Load and generate models "test1.yaml" and "test2.yaml" and then perform
            calculation with generated models "merge(test1, test2)" with saving result
            into a file "model.csv"
        4.  jmaster --models test.yaml --ts model.csv
            Load data from "model.csv" and model from "test.yaml" and produce new
            series of the data, derived from preloaded data and computations of the
            model. Series of data generated from the model, is applying to original data as
            through operators.

"""

YAML = """
# This is an example of the model file. The model begins
# with node "model:"
    model:
      # ID of the model
      id: test1
      # Human-readable name of the model
      name: "Test model"
      # Name of the CSV file for storing generated test data
      fname: test_1.csv
      # Definition of the attributes of the model
      attrs:
        # Attribute name and expression for generation of the column
        - a: "abs(random_normal(1, 12, 10))"
        - b: "abs(random_normal(2, 8, 10))"
      # Definition of the "y" column of the data
      y: "abs(random_normal(0, 4, 10))"
      # Non-mandatory post-processing expressions
      postprocess:
        - "normalize(data)"
"""

def _normalize(data):
    _post = preprocessing.normalize(data)
    _data = pd.DataFrame()
    c = 0
    for k in data:
        _data[k] = _post[c]
        c += 1
    data = _data
    return data

def _merge_df(*datasets):
    root = pd.DataFrame()
    for d in datasets:
        root = root.append(d)
    return root


def _anexpression(_exp, _fun, variables={}):
    parser = expression.Expression_Parser(functions=_fun, variables=variables)
    try:
        return parser.parse(_exp)
    except NameError:
        print("Name error:",colored.red(_exp))
        return None
    except TypeError:
        print("Type error:",colored.red(_exp))
        return None
    except SyntaxError:
        print("Syntax error:",colored.red(_exp))
        return None

def _expression(_exp, variables={}):
    functions = {
        'int': int,
        'odd': lambda x: True if x % 2 == 0 else False,
        'even': lambda x: True if x % 2 == 1 else False,
        'div2': lambda x: x % 2,
        'range': np.arange,
        'abs':abs,
        'sum':np.sum,
        'sin':np.sin,
        'cos':np.cos,
        'log':np.log,
        'log10':np.log10,
        'sqrt':np.sqrt,
        'random_normal': np.random.normal,
        'random_uniform': np.random.uniform,
        'normalize': lambda x: x / np.linalg.norm(x)
    }
    return _anexpression(_exp, functions, variables)

def _lispex(_exp_list, vars):
    vars['np'] = np
    out = {}
    for k in _exp_list:
        _key = list(k.keys())[0]
        _value = k[_key]
        expr = hy.read_str(_value)
        vars[_key] = hy.eval(expr, vars)
        out[_key] = vars[_key]
    return out

def _outexpression(_exp, variables):
    functions = {
        "merge": _merge_df
    }
    res = _anexpression(_exp, functions, variables)
    return res

def _mk_heatmap(namespace, fname, data):
    data.reset_index(inplace=True, drop=True)
    plot = sns.heatmap(data, annot=True, linewidths=.5, cmap="coolwarm", fmt=".1f")
    png_fname = os.path.splitext(fname)[0]+'.png'
    fig = plot.get_figure()
    fig.savefig(png_fname)
    fig.clf()
    plot = sns.catplot(kind="box", data=data)
    png_fname = os.path.splitext(fname)[0]+"_cat"+'.png'
    plot.savefig(png_fname)

def _load_vars_from_model(namespace, model, vars):
    if 'variables' not in model['model']:
        model['model']['variables'] = []
    if 'pre_func' not in model['model']:
        model['model']['pre_func'] = []
    if 'post_func' not in model['model']:
        model['model']['post_func'] = []
    _lispex(model['model']['pre_func'], vars)
    for v in model['model']['variables']:
        _key = list(v.keys())[0]
        _value = v[_key]
        vars[_key] = _expression(_value, vars)
    _lispex(model['model']['post_func'], vars)

def help(namespace, param):
    from pygments.formatters import TerminalFormatter
    from pygments import highlight
    from pygments.lexers.data import YamlLexer
    print(colored.cyan(HELP))
    print(colored.white(EXAMPLES))
    with indent(4):
        puts("Example of the model file:\n")
        with indent(4):
            puts(highlight(YAML, YamlLexer(), TerminalFormatter()))
    sys.exit(0)

def output(namespace, param):
    try:
        dpath.util.set(namespace, "/config/output", param[0])
    except IndexError:
        return namespace
    print("Set output file: ", colored.magenta(param[0]))
    return namespace

def oexp(namespace, param):
    dpath.util.set(namespace, "/config/output_exp", param)
    print("Set output calculations: ", colored.magenta(param))
    return namespace

def exp(namespace, param):
    for e in param:
        _res = _expression(e)
        if _res is None:
            print(colored.red("Does not compute!"))
            continue
        print(colored.magenta(e), colored.white(" = "), colored.yellow(_res))
    return namespace

def tsmodel(namespace, params):
    df = []
    for i in params:
        df.append(pd.read_csv(i))
    c = 0
    models = dpath.util.get(namespace, "/models")
    fname = dpath.util.get(namespace, "/config/output")
    fname = os.path.splitext(fname)[0]
    op = dpath.util.get(namespace, "/config/op")
    op_fun = dpath.util.get(namespace, "/sbin/op")[op]
    for data in df:
        vars = {'data': data, 'shape':data.shape}
        for m in models:
            print("Applying",colored.green(m),"on", colored.green(params[c]), "with",colored.green(op))
            _d = {}
            if 'fun' in models[m]['model']:
                out = _lispex(models[m]['model']["fun"], vars)
                _d.merge(out)
            for e in models[m]['model']["attrs"]:
                _load_vars_from_model(namespace, models[m], vars)
                _exp = list(e.values())[0]
                _key = list(e.keys())[0]
                _mul = _expression(_exp, vars)
                _d[_key] = _mul
            if "y" in models[m]['model']:
                _d["y"] = _expression(models[m]['model']["y"], vars)
            for _ts_step in range(0, data.shape[0]):
                for _col_name in _d:
                    try:
                        data[_col_name] = op_fun(data[_col_name],_d[_col_name][_ts_step])
                    except KeyError as err:
                        print(colored.red("Attribute not found!"), "{}".format(err))
                        raise SystemExit
                if 'y' in data:
                    data["y"] = op_fun(data["y"], _d["y"][_ts_step])
                _current_fname = "{}_{}_{}.csv".format(fname, c, _ts_step)
                data.to_csv(_current_fname, index=False)
                _mk_heatmap(namespace, _current_fname, data)
                print("Saving",colored.green(_current_fname))
        c += 1
    return namespace

def model(namespace, models):
    for m in dpath.util.get(namespace, "/models"):
        model = dpath.util.get(namespace, "/models")[m]['model']
        if 'fun' in model:
            n_of_fun = len(model['fun'])
        else:
            n_of_fun = 0
        n_of_attrs = len(model['attrs']) + n_of_fun
        print(tabulate(
            [["Model:", colored.yellow(m)],
            ["Generating: ", colored.yellow("{} attributes".format(n_of_attrs))]]
        ))
        if n_of_attrs == 0:
            return
        data = pd.DataFrame()
        vars = {'data': data}
        _load_vars_from_model(namespace, dpath.util.get(namespace, "/models")[m], vars)
        with progress.Bar(label=m, expected_size=n_of_attrs) as bar:
            last_val = 0
            if 'fun' in model:
                out = _lispex(model["fun"], vars)
                for k in out:
                    data[k] = out[k]
            for e in model['attrs']:
                _exp = list(e.values())[0]
                _key = list(e.keys())[0]
                bar.show(last_val)
                last_val += 1
                col = _expression(_exp, vars)
                if col is not None:
                    data[_key] = col
        if 'y' in model:
            _exp = model['y']
            print("Calculating Y: ", colored.green(_exp))
            col = _expression(_exp, vars)
            if col is not None:
                data['y'] = col
            else:
                print(colored.red("Failed"))
        else:
            print("Calculating Y: ", colored.cyan("Not defined in model"))
        if 'postprocess' in model:
            for _exp in model['postprocess']:
                print("Postprocessing: ", colored.green(_exp))
                data = _expression(_exp, vars)
        else:
            print("Postprocessing: ", colored.green("Not defined"))
        dpath.util.new(namespace, "/generated/{}".format(m), data)
        data.reset_index()
        try:
            print(colored.white("Save {}".format(model['fname'])))
            data.to_csv(model['fname'], index=False)
            _mk_heatmap(namespace, model['fname'], data)
        except IOError:
            print(colored.red("Can not save {}".format(model['fname'])))
    return namespace

def calculate_output(namespace, params):
    variables = {
        'data': pd.DataFrame()
    }
    variables.update(dpath.util.get(namespace, "/generated"))
    for f in params:
        variables["data"] = _outexpression(f, variables)
    return variables["data"]

def get_params(namespace, name):
    try:
        params = dpath.util.get(namespace, "/config/grouped")['--{}'.format(name)].all
    except KeyError:
        params = []
    return params

def execute_fun(namespace, name, param):
    n = "/sbin/{}".format(name)
    try:
        print(colored.white("Executing "), colored.green("{}".format(n)))
        fun = dpath.util.get(namespace, n)
    except KeyError:
        print(colored.red("Can not excute {}".format(n)))
    namespace = fun(namespace, param)
    return namespace

def main():
    print(colored.white("Generating test datasets"))
    namespace = {}
    dpath.util.new(namespace, "/config/args", Args())
    dpath.util.new(namespace, "/config/flags", dpath.util.get(namespace, "/config/args").flags)
    dpath.util.new(namespace, "/config/grouped", dpath.util.get(namespace, "/config/args").grouped)
    dpath.util.new(namespace, "/config/output", "output.csv")
    dpath.util.new(namespace, "/config/output_exp", [])
    dpath.util.new(namespace, "/config/op", 'multiply')
    dpath.util.new(namespace, "/models", {})
    dpath.util.new(namespace, "/generated", {})
    dpath.util.new(namespace, "/bin/help", help)
    dpath.util.new(namespace, "/bin/exp", exp)
    dpath.util.new(namespace, "/bin/output", output)
    dpath.util.new(namespace, "/bin/oexp", oexp)
    dpath.util.new(namespace, "/sbin/model", model)
    dpath.util.new(namespace, "/sbin/ts", tsmodel)
    dpath.util.new(namespace, "/sbin/op", {'multiply':np.multiply, 'plus': np.add, 'minus':np.subtract, 'divide': np.divide})
    dpath.util.new(namespace, "/sbin/output", calculate_output)
    files = get_params(namespace, 'models')
    ts = get_params(namespace, 'ts')
    files = [i for i in files if posixpath.exists(i) and posixpath.isfile(i)]
    ts = [i for i in ts if posixpath.exists(i) and posixpath.isfile(i)]
    op = get_params(namespace, 'op')
    if len(op) == 0:
        op = 'multiply'
    else:
        op = op[0]
        if op not in dpath.util.get(namespace, "/sbin/op"):
            print(colored.red("Can not recognize operation for --ts mode: {}".format(op)))
            print(colored.red("Valid options are: {}".format(list(dpath.util.get(namespace, "/sbin/op").keys()))))
            return
    dpath.util.set(namespace, "/config/op", op)
    dpath.util.new(namespace, "/config/ts", ts)
    dpath.util.new(namespace, "/config/files", files)

    print("Considering", colored.green("{}".format(len(files))), "model(s)")
    for f in files:
        with open(f, 'r') as _f:
            try:
                y = yaml.safe_load(_f)
            except yaml.YAMLError as exc:
                continue
            if 'model' not in y:
                continue
            _isGood = True
            for i in ['fname', 'attrs', 'id']:
                if i not in y['model']:
                    print("Model {} no good: ".format(f), colored.red("{} attribute is missing".format(i)))
                    _isGood = False
                    break
            for i in ['y']:
                if i not in y['model']:
                    print("Model {} may not be complete: ".format(f), colored.cyan("{} attribute is missing".format(i)))
            if _isGood is not True:
                continue
            dpath.util.new(namespace, "/models/{}".format(y['model']['id']), y)
    for f in dpath.util.get(namespace, "/config/flags").all:
        try:
            fun = dpath.util.get(namespace, "/bin/{}".format(f[2:].lower()))
        except KeyError:
            continue
        except IndexError:
            continue
        param = dpath.util.get(namespace, "/config/grouped/{}".format(f)).all
        namespace = fun(namespace, param)
    if len(ts) > 0:
        namespace = execute_fun(namespace, "ts", ts)
    else:
        namespace = execute_fun(namespace, "model", files)
    output_exp = dpath.util.get(namespace, "/config/output_exp")
    if len(output_exp) != 0:
        fname = output_exp = dpath.util.get(namespace, "/config/output")
        print("Calculating output to: ", colored.green(fname))
        fun = dpath.util.get(namespace, "/sbin/output")
        data = fun(namespace, dpath.util.get(namespace, "/config/output_exp"))
        data.reset_index()
        print("Saving output to: ", colored.green(fname))
        data.to_csv(fname, index=False)
        _mk_heatmap(namespace, fname, data)
    return

if __name__ == '__main__':
    main()
